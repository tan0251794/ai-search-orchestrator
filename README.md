# ğŸ“– AI Search Summarizer App

**Live Demo:** ğŸ‘‰ [https://www.tanly.blog](https://www.tanly.blog) ğŸ‘ˆ  

## ğŸš€ Introduction
AI Search Summarizer is a **smart search application** that allows users to enter any topic, the system will:  
1. **Automatically crawl Google** (using Selenium).  
2. **Send multiple prompts in parallel (10 prompts)** to AI for the most accurate information.  
3. **AI Summarizer** aggregates and condenses the content into a short, easy-to-read result.  

The application saves time for research while ensuring more complete and accurate information compared to just reading raw search results.  

---

## ğŸ— System Architecture

![System Architecture](./system-chart.png)

![Module Architecture](./flow-chart.png)

---

## âš™ï¸ Main Components

### ğŸŒ Frontend
- **React WebApp**
  - Collects queries from users.  
  - Sends requests to the backend.  
  - Displays summarized results + next query suggestions.  

### âš™ï¸ Backend (EC2 + Docker)
- **API Gateway / Nginx**: receives requests from FE, routes to services.  
- **AI Orchestrator**: coordinates the pipeline, calls crawler + AI.  
- **Session & Cache Manager**: manages session, caches queries for optimization.  

### ğŸ“Š Data Sources
- **Google Search (Selenium on EC2)**: crawls data from Google Search.  
- **AI Models (Dockerized / Bedrock API)**: runs multi-prompt analyzer + summarizer.  
- **S3 + PostgreSQL**: stores crawled data, query history, and session states.  

---

## ğŸ”„ Workflow
1. User enters a query on the **Frontend**.  
2. Request is sent to **Backend (API Gateway)**.  
3. **AI Orchestrator** triggers the **Selenium Crawler** to fetch Google Search data.  
4. Collected content is sent to the **Multi-Prompt Analyzer** (10 prompts in parallel).  
5. Results are aggregated by the **Summarizer** into a short summary.  
6. Final result + suggestions are returned to the **Frontend**.  

---

## ğŸ³ Deployment with Docker + EC2

### 1. Requirements
- AWS EC2 instance (Ubuntu 22.04).  
- Docker & Docker Compose installed.  
- Domain + SSL (via Nginx).  

### 2. Clone the project
```bash
git clone https://github.com/your-org/ai-search-summarizer.git
cd ai-search-summarizer
```

### 3. Run with Docker Compose
```bash
docker-compose up -d --build
```

### 4. Configure ENV
Create a `.env` file:
```env
POSTGRES_USER=aiapp
POSTGRES_PASSWORD=securepass
POSTGRES_DB=ai_search
OPENAI_API_KEY=your_openai_api_key
```

### 5. Access
- FE: `http://your-domain.com`  
- API: `http://your-domain.com/api`  

---

## ğŸŒŸ Key Features
- âœ… Real-time Google Search crawling.  
- âœ… Multiple prompts in parallel â†’ more accurate info.  
- âœ… AI Summarizer aggregates results into a short summary.  
- âœ… Session/Cache for performance optimization.  
- âœ… Quick deployment with Docker on EC2.  

```
ai-search-summarizer/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ frontend/                          # ğŸŒ React WebApp
â”‚   â”œâ”€â”€ Dockerfile                     # Dockerfile for FE
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js / next.config.js
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.tsx
â”‚       â”œâ”€â”€ main.tsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ SearchBox.tsx
â”‚       â”‚   â”œâ”€â”€ ResultsView.tsx
â”‚       â”‚   â””â”€â”€ Suggestions.tsx
â”‚       â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ Home.tsx
â”‚       â”‚   â””â”€â”€ History.tsx
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ api.ts                 # Call Django API
â”‚
â”œâ”€â”€ backend/                           # âš™ï¸ Django Backend
â”‚   â”œâ”€â”€ Dockerfile                     # Dockerfile for BE
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ ai_backend/                    # Django project core
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â”‚
â”‚   â”œâ”€â”€ apps/
â”‚   â”‚   â”œâ”€â”€ search/                    # Search App
â”‚   â”‚   â”‚   â”œâ”€â”€ views.py               # /search endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ summarize/                 # Summarizer App
â”‚   â”‚   â”‚   â”œâ”€â”€ views.py               # /summarize endpoint
â”‚   â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ history/                   # Query history
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py              # PostgreSQL models
â”‚   â”‚   â”‚   â”œâ”€â”€ views.py               # /history endpoint
â”‚   â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ orchestrator/              # Orchestrator (AI + Crawler)
â”‚   â”‚       â”œâ”€â”€ crawler.py             # Selenium crawler function
â”‚   â”‚       â”œâ”€â”€ analyzer.py            # Multi-prompt analyzer
â”‚   â”‚       â”œâ”€â”€ summarizer.py          # AI summarizer
â”‚   â”‚       â””â”€â”€ cache.py               # Redis/Django cache
â”‚   â”‚
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_search.py
â”‚
â””â”€â”€ infrastructure/
    â””â”€â”€ nginx/
        â””â”€â”€ nginx.conf                 # Reverse proxy
```
